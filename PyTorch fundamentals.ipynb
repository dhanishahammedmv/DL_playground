{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b5e61d-f5a1-4ac9-bbae-a48aa450f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dhani\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhani\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ad83a3-6053-4b77-b086-9ea39a4fffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f35045d-cafd-4022-8750-375a05dc8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "558bda83-c1d2-4158-b1e4-c10a11dd81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "7f1e169b-a5ed-4221-8efc-763d6f16fc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b3847650-091f-4afb-9310-b16457d6f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b81fd787-eda7-44ea-a035-b68132d256bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "73653ffa-dc8a-404a-9c82-4c70177bd78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=torch.tensor([5,5])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "56747e5f-8718-4c1a-99b5-17d6190ea38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7acbca58-1e62-4e4f-9c05-595b0ed88e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "60f2b5d5-52bd-4d4c-8b8c-564a928d59e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix=torch.tensor([[1,2],[3,4]])\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c580bdb6-ddde-43b3-add0-d358c58d37d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "15f2654a-8753-40ff-ab1d-1fd0b3422932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a87e6ed2-73f4-4ffc-9f1e-77ef434015cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ac0fb33f-e93f-4950-8ac3-941e7b1643ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d20c531e-bb47-43d4-be3a-4056e709a493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0ee1c0c9-34a4-483d-92fd-011a54250339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1c613-ccfe-4f2e-8b64-206b851d7586",
   "metadata": {},
   "source": [
    "# Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "12c8eb32-b964-4274-abda-753b5392aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9020, 0.6097, 0.3405, 0.4795, 0.0642, 0.0278],\n",
       "        [0.1513, 0.0163, 0.8290, 0.3250, 0.3650, 0.0694],\n",
       "        [0.5828, 0.4250, 0.1596, 0.8206, 0.9215, 0.1436],\n",
       "        [0.7833, 0.4188, 0.4953, 0.7128, 0.4088, 0.9248]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(4,6))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a2ceaff1-c13c-490b-b1e0-e827c54cfb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c984a28c-4ec5-4d78-85e7-abd806112f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ec14f211-6f46-4a04-ad85-d425c6b101f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1d38870e-1164-46ac-8a81-c5afded7a862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8076, 0.1754, 0.1957, 0.0046, 0.6601, 0.1239],\n",
       "         [0.0809, 0.1795, 0.0057, 0.0929, 0.9460, 0.7793],\n",
       "         [0.9430, 0.2575, 0.2949, 0.3246, 0.5098, 0.1411],\n",
       "         [0.5733, 0.1796, 0.5790, 0.9580, 0.5844, 0.8647]],\n",
       "\n",
       "        [[0.1439, 0.4294, 0.1913, 0.4445, 0.3011, 0.2161],\n",
       "         [0.0170, 0.3146, 0.5670, 0.4120, 0.0343, 0.8756],\n",
       "         [0.8707, 0.1985, 0.5508, 0.8320, 0.0252, 0.0582],\n",
       "         [0.7774, 0.4901, 0.6592, 0.2921, 0.5907, 0.8316]],\n",
       "\n",
       "        [[0.3777, 0.3385, 0.0239, 0.4228, 0.8168, 0.0275],\n",
       "         [0.4614, 0.8645, 0.3573, 0.3153, 0.3492, 0.2974],\n",
       "         [0.5598, 0.0186, 0.6911, 0.3737, 0.4363, 0.4663],\n",
       "         [0.7793, 0.1894, 0.0450, 0.1383, 0.1332, 0.2566]]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_0 = torch.rand(size=(3,4,6))\n",
    "random_tensor_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f92bd9b2-4f40-4984-b7a7-61e6baf36991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([3, 4, 6]))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_0.ndim, random_tensor_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "59ee19d4-9990-4ce7-b911-7c1f59e1229d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size = (4,6))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7f8259fc-0d12-4bf6-b096-8a01af44e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (4,6))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870bcdf-9079-47a0-b3e7-50e6ecfc6bd9",
   "metadata": {},
   "source": [
    "# Creating a range of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ac7eb605-cf47-41a0-895f-0d6768425ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0,10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "402447cf-be3c-4ee9-9cc9-3bdd1b497513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.zeros_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc1493-3b06-4724-83c6-16f9c24dc328",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "50a6e92a-ed8a-4fe7-95ab-2c0147fe95af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "t+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c4d370b8-a21c-4661-90aa-a950aa757719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f9655571-1381-4efc-b548-73606967be51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t*t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1c7beb1c-7660-4e91-9d77-440a6da8e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a1a37120-2fd9-4ecc-a9de-bdb332c28ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemantwise addition of a and b: \n",
      " tensor([4., 6.])\n",
      "matrix multiplication of a and b:\n",
      "  tensor([[3., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "b = torch.tensor([3.0, 4.0])\n",
    "\n",
    "print(\"Elemantwise addition of a and b: \\n\", a+b)\n",
    "\n",
    "print('matrix multiplication of a and b:\\n ', torch.matmul(a.view(2,1), b.view(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf702fee-3fff-461d-97ac-250002fdc55f",
   "metadata": {},
   "source": [
    "# Reshaping, Resizing, Transposing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "611e4e3d-1aa1-419a-abf8-8b75f51b28e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping: \n",
      " tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3,4],\n",
    "                  [5,6,7,8],\n",
    "                  [9,10,11,12]])\n",
    "\n",
    "print(\"Reshaping: \\n\", t.reshape(6,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a576b319-fa6e-41ea-81ba-8f209d6424a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing: \n",
      " tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Resizing: \\n\", t.view(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f72a62ee-0dad-448e-b2e7-793d655bdf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposing: \n",
      " tensor([[ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11],\n",
      "        [ 4,  8, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Transposing: \\n\", t.transpose(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3e33e-c38f-4641-9783-c43cdbf49507",
   "metadata": {},
   "source": [
    "# Seed in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e2154417-170c-413f-9a3d-dfb016c7e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8949, 0.1132, 0.2061, 0.0924],\n",
      "        [0.2488, 0.4860, 0.1951, 0.5053],\n",
      "        [0.6690, 0.4149, 0.7157, 0.6147]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.9830, 0.4745, 0.9334, 0.8742],\n",
      "        [0.7390, 0.7830, 0.1651, 0.1651],\n",
      "        [0.7135, 0.6816, 0.9512, 0.4349]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9402e9fa-d97c-48ec-829c-d20b8f0d0377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed=42\n",
    "torch.manual_seed(seed=random_seed)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.random.manual_seed(seed=random_seed) \n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b3eac-0ea5-4518-bb40-f956a2da5d18",
   "metadata": {},
   "source": [
    "# Building neural networks in pytoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6c9da45a-9113-44b3-b051-c14834b2bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # To define neural network layers and models\n",
    "import torch.optim as optim # Optimizer for training(like SGD, Adam etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7072fcc9-a907-44a5-9dac-ad4e0ab22414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      " NeuralNetwork(\n",
      "  (fc1): Linear(in_features=10, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [5/20], Loss: 0.6796\n",
      "Epoch [10/20], Loss: 0.6623\n",
      "Epoch [15/20], Loss: 0.6313\n",
      "Epoch [20/20], Loss: 0.5885\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.fc1 = nn.Linear(10,16) # first layer\n",
    "    self.fc2 = nn.Linear(16,8)  # 2nd layer\n",
    "    self.fc3 = nn.Linear(8,1)   # 3rd layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = torch.sigmoid(self.fc3(x))\n",
    "    return x\n",
    "\n",
    "#Model setup\n",
    "model = NeuralNetwork()\n",
    "print(\"Model: \\n\", model)\n",
    "\n",
    "#Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01)\n",
    "\n",
    "inputs = torch.randn((100,10))\n",
    "targets = torch.randint(0,2,(100,1)).float()\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  optimizer.zero_grad()   #clear old gradients\n",
    "  outputs = model(inputs)\n",
    "  loss = criterion(outputs, targets)  # compute loss between prediction and target\n",
    "  loss.backward()   # Backward pass: Computes gradient of loss w.r.t. weight.\n",
    "  optimizer.step()  # Update weight to reduce the loss\n",
    "\n",
    "  if (epoch+1) % 5 == 0:\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9c3622d8-4e94-4f51-8572-85cc6485944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model parameters:  [Parameter containing:\n",
      "tensor([-1.2490], requires_grad=True)]\n",
      "Epoch 0, Loss: 42.22442626953125, weght: -0.9890949726104736\n",
      "Epoch 10, Loss: 41.96862030029297, weght: 5.257591724395752\n",
      "Epoch 20, Loss: 34.40822219848633, weght: -1.2280254364013672\n",
      "Epoch 30, Loss: 22.246994018554688, weght: 4.903101444244385\n",
      "Epoch 40, Loss: 9.834027290344238, weght: -0.31254899501800537\n",
      "Epoch 50, Loss: 1.6084543466567993, weght: 3.510403633117676\n",
      "Epoch 60, Loss: 0.5118977427482605, weght: 1.4299404621124268\n",
      "Epoch 70, Loss: 6.9365081787109375, weght: 1.5775556564331055\n",
      "Epoch 80, Loss: 18.5847110748291, weght: 3.3762948513031006\n",
      "Epoch 90, Loss: 31.290882110595703, weght: -0.2042173147201538\n",
      "Final Model Parameters:  [Parameter containing:\n",
      "tensor([5.1824], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleNet, self).__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(1, requires_grad = True))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x * self.weight\n",
    "\n",
    "model = SimpleNet()\n",
    "print(\"Initial model parameters: \", list(model.parameters()))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "input_tensor = torch.tensor([2.0])\n",
    "target_tensor = torch.tensor([4.0])\n",
    "\n",
    "for epoch in range(100):\n",
    "  optimizer.zero_grad \n",
    "  output = model(input_tensor)\n",
    "  loss = criterion(output, target_tensor) \n",
    "  loss.backward() \n",
    "  optimizer.step()  \n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}, weght: {model.weight.item()}\")\n",
    "\n",
    "print(\"Final Model Parameters: \", list(model.parameters()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
