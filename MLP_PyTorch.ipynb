{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZFijXmGakFg"
      },
      "outputs": [],
      "source": [
        "import gzip #for zip file\n",
        "import pickle  #Uses pickle to load the Python objects stored in mnist.\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim #nn - neural network [eg: nn.linear()], optim - optimizer [eg: optim.Adam()]\n",
        "import torch.nn.functional as F  #Give acces to activation functions [eg: F.relu(), F.softmax() etc]\n",
        "from torch.utils.data import TensorDataset, DataLoader  #TensorDataset: wrap input tensors and target tensors into dataset object\n",
        "                                                        #DataLoader to load data batches, shuffle it and iterate over it during training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  with gzip.open('mnist.pkl.gz', 'rb') as file:\n",
        "    training_set, validation_set, testing_set = pickle.load(file, encoding = 'latin')\n",
        "\n",
        "  def tensor_data(data):\n",
        "    x = torch.tensor(data[0], dtype=torch.float32) #images - [num_samples,784]\n",
        "    y = torch.tensor(data[1], dtype=torch.long) #labels - [num_samples]\n",
        "    return TensorDataset(x,y) #returns (images, labels)\n",
        "\n",
        "  return tensor_data(training_set), tensor_data(validation_set), tensor_data(testing_set)"
      ],
      "metadata": {
        "id": "9Wrweb8Tbl5Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "  \"\"\"multiplied with 0.01 makes the weights smaller hence avoind exploding gradient\n",
        "     .clone().detach() makes sure that the tensor is fresh copy and not associated with any previous computation graph\n",
        "     .requires_grad_() tracks gradient so that these can be updated during training\"\"\"\n",
        "  W_1 = (torch.randn(784, 128)*0.01).clone().detach().requires_grad_()\n",
        "  b_1 = torch.zeros(128, requires_grad=True)\n",
        "  W_2 = (torch.randn(128, 64)*0.01).clone().detach().requires_grad_()\n",
        "  b_2 = torch.zeros(64, requires_grad=True)\n",
        "  W_3 = (torch.randn(64, 10)*0.01).clone().detach().requires_grad_()\n",
        "  b_3 = torch.zeros(10, requires_grad=True)\n",
        "  return [W_1, b_1, W_2, b_2, W_3, b_3]\n",
        "\n",
        "def forward(x, parameters):\n",
        "  W_1, b_1, W_2, b_2, W_3, b_3 = parameters\n",
        "  x = F.relu(x @ W_1 + b_1)\n",
        "  x = F.relu(x @ W_2 + b_2)\n",
        "  x = x @ W_3 + b_3\n",
        "  return x"
      ],
      "metadata": {
        "id": "52QZZe9fp7bt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target):\n",
        "  preds = output.argmax(dim=1)\n",
        "  return (preds==target).float().mean().item()\n",
        "\n",
        "def train(training_loader, validation_loader, parameters, epochs = 10, lr = 0.1):\n",
        "  optimizer = optim.SGD(parameters, lr)\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    for x,y in training_loader:\n",
        "\n",
        "      \"\"\"Forward pass and loss\"\"\"\n",
        "      output = forward(x, parameters)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "\n",
        "      \"\"\"Backpropogation and update\"\"\"\n",
        "      optimizer.zero_grad() #clear old gradients\n",
        "      loss.backward()  #Compute new gradients\n",
        "      optimizer.step() #updates weights\n",
        "\n",
        "      \"\"\"Total loss\"\"\"\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "    evaluation_model(validation_loader, parameters, name=\"Validation\")\n",
        "\n",
        "def evaluation_model(loader, parameters, name=\"Test\"):\n",
        "  correct=0\n",
        "  total = 0\n",
        "  with torch.no_grad(): #no gradient needed\n",
        "    for x, y in loader:\n",
        "      output = forward(x,parameters)\n",
        "      pred = output.argmax(dim=1)\n",
        "      correct += (pred == y).sum().item()\n",
        "      total += y.size(0)\n",
        "  accuracy = (correct/total) * 100\n",
        "  print(f\"{name} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "training_data, validation_data, testing_data = load_data()\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle = True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64)\n",
        "testing_loader = DataLoader(testing_data, batch_size=64)\n",
        "parameters = initialize_parameters()\n",
        "train(training_loader, validation_loader, parameters, epochs=10, lr=0.1)\n",
        "evaluation_model(testing_loader, parameters, name=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-3nEeCAjhlj",
        "outputId": "7fa83727-8a41-4ea7-9035-329cbdf2c00f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1177.0869\n",
            "Validation Accuracy: 83.46%\n",
            "Epoch 2, Loss: 291.6430\n",
            "Validation Accuracy: 92.98%\n",
            "Epoch 3, Loss: 166.1100\n",
            "Validation Accuracy: 92.92%\n",
            "Epoch 4, Loss: 120.2431\n",
            "Validation Accuracy: 96.05%\n",
            "Epoch 5, Loss: 94.8618\n",
            "Validation Accuracy: 96.54%\n",
            "Epoch 6, Loss: 78.1741\n",
            "Validation Accuracy: 96.66%\n",
            "Epoch 7, Loss: 65.2059\n",
            "Validation Accuracy: 96.90%\n",
            "Epoch 8, Loss: 55.4272\n",
            "Validation Accuracy: 97.13%\n",
            "Epoch 9, Loss: 48.8235\n",
            "Validation Accuracy: 97.55%\n",
            "Epoch 10, Loss: 41.8411\n",
            "Validation Accuracy: 96.78%\n",
            "Test Accuracy: 96.77%\n"
          ]
        }
      ]
    }
  ]
}